{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for social neural population decoding (NPD)\n",
    "With inspiration from:\n",
    "\"The geometry of hippocampal CA2 representations enables abstract coding of social familiarity and identity\" - Boyle 2022\n",
    "\n",
    "**Note!** The analysis needs to be repeated for *each animal separately*, and only persistent units across all selected actions will be included in the analysis. This because the input to an SVM is interpreted as a vector of unique units. Hence units from an animal B can not replace the input of an SVM trained on units from animal A. Lastly, this notebook trains SVMs to predict social interactions. Other notebooks try to decode trial and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.style.use('../bioAI.mplstyle')\n",
    "import expipe\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append('../ca2-mec') if '../ca2-mec' not in sys.path else None \n",
    "import dataloader as dl\n",
    "from utils import *\n",
    "from plotting_functions import *\n",
    "from methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396791dba23b443bac8dffd4515bce3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='', placeholder='Search'), Select(layout=Layout(height='200px'), optiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = expipe.get_project(dl.project_path())\n",
    "project.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load #spikes:  61\n",
      "#units after mua-corrections: 61\n",
      "#units after brain region selection: 61\n",
      "Num spike_trains: 60. Num persistent units: 12\n"
     ]
    }
   ],
   "source": [
    "lim = [0,1200] # limit recording times - in seconds\n",
    "\n",
    "#CA2 - rotte 001:\n",
    "#include_actions = ['001-181220-2', '001-181220-3', '001-181220-4', '001-181220-5', '001-181220-6', '001-191220-1', '001-191220-3', '001-191220-6', '001-191220-7', '001-191220-8'] # choose actions to include\n",
    "#include_actions = ['001-191220-1', '001-191220-3', '001-191220-6', '001-191220-7', '001-191220-8']\n",
    "include_actions = ['001-181220-2', '001-181220-3', '001-181220-4', '001-181220-5', '001-181220-6']\n",
    "\n",
    "#CA2 rotte 007:\n",
    "#include_actions = ['007-081221-1', '007-081221-2', '007-081221-3', '007-081221-4', '007-081221-5', '007-081221-6']\n",
    "\n",
    "#CA2 - rotte 011:\n",
    "#include_actions = ['011-120321-2', '011-120321-3', '011-120321-4', '011-120321-5', '011-120321-6']\n",
    "\n",
    "#include_actions = ['022-160322-1', '022-160322-2', '022-160322-3', '022-160322-4', '022-160322-5', '022-160322-7']\n",
    "\n",
    "#CA1 - rotte 144:\n",
    "#include_actions = ['144-100621-1', '144-100621-2', '144-100621-3', '144-100621-4', '144-100621-5']\n",
    "\n",
    "# Cast assertion error if include_actions contain actions from multiple entities. \n",
    "animal_entity = include_actions[0].split('-')[0]\n",
    "multiple_entities = all([animal_entity in action_id for action_id in include_actions])\n",
    "assert multiple_entities, \"Requires only actions from same animal entity! Read start of notebook!\"\n",
    "\n",
    "spikes = []\n",
    "tracking = {}\n",
    "for action_id in include_actions:\n",
    "    spikes += dl.load_spiketrains(action_id, lim=lim, identify_neurons=True)\n",
    "    tracking[action_id] = dl.load_tracking(action_id, lim=lim, ca2_transform_data=True) # only get positions\n",
    "    \n",
    "print(\"load #spikes: \", len(spikes))\n",
    "    \n",
    "# correct for inconsistent mua-annotations\n",
    "spikes = dl.correct_mua(spikes, only_good_mua=False)\n",
    "print(\"#units after mua-corrections:\", len(spikes))\n",
    "spatial_map = sp.SpatialMap()\n",
    "\n",
    "# SELECT brain region(s) to include cells from\n",
    "spikes = dl.in_brain_regions(spikes, ['ca2']) #lec #ca2 #ca1\n",
    "print(\"#units after brain region selection:\", len(spikes))\n",
    "\n",
    "# only include cells that are persistent across all actions\n",
    "spikes = dl.persistent_units(spikes, include_actions)\n",
    "npersistent = int(len(spikes) / len(include_actions))\n",
    "print(f\"Num spike_trains: {len(spikes)}. Num persistent units: {npersistent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup input data and labels\n",
    "This should follow the format:\n",
    "- X.shape = (samples, num_features) -> neural rate activity\n",
    "- y.shape = (samples) -> scalars indicating labelled class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort spikes on unit_idnum and action_id, respectively\n",
    "spikes.sort(key=lambda spike_train: spike_train.annotations['unit_idnum'])\n",
    "spikes.sort(key=lambda spike_train: spike_train.annotations['action_id'])\n",
    "unit_idnums = np.unique([spike_train.annotations[\"unit_idnum\"] for spike_train in spikes])\n",
    "\n",
    "# print the spike properties that the spikes list has been sorted on to confirm sorting\n",
    "#[(spike_train.annotations[\"action_id\"], spike_train.annotations[\"unit_idnum\"]) for spike_train in spikes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'include_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1f7e58d831e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#X,y_true = Xy_social(spikes,tracking,categories_to_include,input_dim=npersistent,window_size=window_size,res=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#X,y_true = Xy_spatial(spikes,tracking,categories_to_include,input_dim=npersistent,window_size=window_size,res=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXy_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspikes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategories_to_include\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnpersistent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\apps\\CA2_MEC\\ca2-mec\\methods.py\u001b[0m in \u001b[0;36mXy_trial\u001b[1;34m(spikes, tracking, categories_to_include, input_dim, window_size, res)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# set trial label - all labels for an action has the same label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0my_tmp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minclude_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'include_actions' is not defined"
     ]
    }
   ],
   "source": [
    "categories_to_include = [0, 1] # <--- SELECT categories to include\n",
    "window_size=0.5 # boyle2022 used 100ms\n",
    "\n",
    "#X,y_true = Xy_social(spikes,tracking,categories_to_include,input_dim=npersistent,window_size=window_size,res=10)\n",
    "#X,y_true = Xy_spatial(spikes,tracking,categories_to_include,input_dim=npersistent,window_size=window_size,res=10)\n",
    "X,y_true = Xy_trial(spikes,tracking,categories_to_include,input_dim=npersistent,window_size=window_size,res=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the range of rates an input can take, and how often these appear.\n",
    "# first row: number of spikes within time window\n",
    "# second row: number of occurences a unit has this many spikes\n",
    "np.unique(X, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show firing rate distributions (histogram) for each neuron in different categories\n",
    "We look at these plots to get an intuition for whether there the data distributions seem to be different from each other depending on the (labelled) category of the data. If they are different, we would expect the data to at least be somewhat separable. If the data distributions are not different this does **not** mean the data is not seperable. In this case, however, there would have to be some ordering within the data wrt. the labels that makes the data separable. In the final case, the data may be separable when we have a model with very high complexity - then even random shuffeling of the data labels could be separable by such models.\n",
    "\n",
    "**NOTE!** Changing the parameter \"density\" between \"True\" and \"False\" gives two different intutions:\n",
    "1. True -> Gives a feeling for the similarity in distributions between the two categories\n",
    "2. False -> Gives a feeling HOW MUCH DATA are within each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nfeatures = X.shape[-1]\n",
    "ncategories = len(categories_to_include)\n",
    "fig,axs = plt.subplots(nrows=nfeatures,figsize=(4,nfeatures*2))\n",
    "nbins=20\n",
    "bins = np.linspace(np.min(X), np.max(X), nbins+1)\n",
    "for j, category in enumerate(categories_to_include):\n",
    "    [axs[i].hist(X[:,i][y_true == category],bins=bins,alpha=0.4,label=f\"C={category}\",density=True) for i in range(nfeatures)]\n",
    "[axs[i].set_title(f\"Neuron={unit_idnums[i]}\") for i in range(nfeatures)]\n",
    "[axs[i].legend() for i in range(nfeatures)];\n",
    "[axs[i].set_xticks([]) for i in range(nfeatures-1)]\n",
    "axs[-1].set_xlabel(\"Rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, balanced_accuracy_score\n",
    "\n",
    "#Sette opp modell for SVM (-> output gives accuracy based on c value that gives best balanced accuracy score):\n",
    "def modeltrain(X, y_true):\n",
    "    test_size=0.25 # boyle2022 used 0.25\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=test_size, random_state=0, stratify=y_true) #med stratify=y_true sÃ¥ sÃ¸rger vi for Ã¥ ha data fra alle kategorier i bÃ¥de training og test data \n",
    "    c_candidates = [10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]\n",
    "    c_accuracy = []\n",
    "    for c in c_candidates: #Regularisering testing (calculating accuracy for c values in \"c_candidates\" and listing in c_accuracy)\n",
    "        X_eval, X_val, y_eval, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0)\n",
    "        clf = make_pipeline(StandardScaler(), SVC(kernel='linear', C=c, class_weight='balanced'))\n",
    "        clf.fit(X_eval, y_eval)\n",
    "        c_accuracy.append(balanced_accuracy_score(y_val,clf.predict(X_val),adjusted=False)) #clf.score(X_val,y_val))\n",
    "\n",
    "\n",
    "    best_c=np.argmax(c_accuracy) #c value that gives the best accuracy value for this data set \n",
    "    clf = make_pipeline(StandardScaler(), SVC(kernel='linear', C=c_candidates[best_c], class_weight='balanced'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    return X_train, X_test, y_train, y_test, clf\n",
    "    #evt ogsÃ¥ return:  clf.score(X_test,y_test), f1_score(y_test, clf.predict(X_test),pos_label=1)\n",
    "    \n",
    "#Sette opp modell for shuffled balanced accuracy verdier\n",
    "def shuffled_modeltrain(X, y_true):\n",
    "    y_shuffled= y_true.copy()\n",
    "    random.shuffle(y_shuffled)\n",
    "    X_train, X_test, y_train, y_test, clf = modeltrain(X, y_shuffled)\n",
    "    return [clf.score(X_test,y_test), balanced_accuracy_score(y_test, clf.predict(X_test),adjusted=False)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vi kjÃ¸rer SVM modellen (clf) som er satt opp i cellen fÃ¸r og fÃ¥r ut balanced accuracy-verdi (\"model_Baccuracy_score\"):\n",
    "\n",
    "X_train, X_test, y_train, y_test, clf = modeltrain(X, y_true)\n",
    "clf.score(X_test,y_test) \n",
    "\n",
    "model_Baccuracy_score=balanced_accuracy_score(y_test, clf.predict(X_test), adjusted=False) #obs pÃ¥ om vi setter label 0 eller 1 (gir ulik f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling to estimate chance:\n",
    "shuffled_results = Parallel(n_jobs=-1)(delayed(shuffled_modeltrain)(X,y_true) for i in range(20)) #-1 betyr at vi bruker alle kjerner maskinen har. 1 = 1, 2= 2 osv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting p values\n",
    "shuffled_Baccuracy=[]\n",
    "shuffled_accuracy=[]\n",
    "for shuffled in shuffled_results:\n",
    "    shuffled_accuracy.append(shuffled[0])\n",
    "    shuffled_Baccuracy.append(shuffled[1])\n",
    "#np.percentile(shuffled_f1,95)\n",
    "\n",
    "sortedshuffled_Baccuracy = np.sort(shuffled_Baccuracy)-model_Baccuracy_score\n",
    "np.min([(sum(sortedshuffled_Baccuracy>0)+1)/len(sortedshuffled_Baccuracy), 1]) #p value=0.2 means\"below 0.2\" = vi setter Ã¸vre p-verdi. np.min so p_value is never above 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.histogram(shuffled_Baccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shuffled_Baccuracy)\n",
    "print(np.mean(shuffled_Baccuracy))\n",
    "print(np.mean(shuffled_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at predictions and label histograms in training and test sets\n",
    "This gives an intuition for two things:\n",
    "1. That the training set is representative (looks the same) of the test set in terms of the labels\n",
    "2. (i) That the classifier (model) predicts events in both categories, and (ii) how it relates to the labelled distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(ncols=2)\n",
    "\n",
    "y_hat_test = clf.predict(X_test)\n",
    "axs[0].hist(y_hat_test, alpha=0.4,label=\"Pred\")\n",
    "axs[0].hist(y_test, alpha=0.4, label=\"True\")\n",
    "axs[0].set_title(\"y-TEST distribution\")\n",
    "axs[0].legend()\n",
    "\n",
    "y_hat_train = clf.predict(X_train)\n",
    "axs[1].hist(y_hat_train, alpha=0.4, label=\"Pred\")\n",
    "axs[1].hist(y_train, alpha=0.4, label=\"True\")\n",
    "axs[1].set_title(\"y-TRAIN distribution\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "Gives an overview of the distribution of prediction-label categories: True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN). Note that this is for the binary classification setting. If the classes are labelled e.g. 1 and 2, then: TP = (1,1), TN = (2,2), FP = (1,2), and FN = (2,1), if we consider 1s as \"positives\" and 2s as \"negatives\". In the ideal case, the classifier (model) would correctly classify all instances (both positives and negatives), which would result in only events (100%) in the TP = (1,1) and TN = (2,2) cases. In \"the worst\" scenario, the classifier only predicts one label for all inputs (clever but boring and lazy classifier that only picks the \"most likely\" class, regardless of what input it gets). This can be seen in the confusion matrix by assigning all predictions to either the positive (1) or negative (2) classes. In other words, assuming the classifier always predicts positives (1), then TP + FP = 1, and TN + FN = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"Categories: {categories}.\", \"Probability of category:\", counts/np.sum(counts))\n",
    "print(\"\\n SVM score: Accuracy \", round(clf.score(X_test,y_test),3))\n",
    "if len(categories) == 2:\n",
    "    print(\"Balanced Accuracy score\", round(balanced_accuracy_score(y_test, clf.predict(X_test),adjusted=False),3))\n",
    "_ = plot_confusion_matrix(clf, X_test, y_test, normalize='true', cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Neuron Importance\n",
    "Rank the importance a neuron has on the classification task. Here, we consider \"importance\" to be synonomous with SVM linear layer weight magnitudes. Geometrically this amounts to \"how orthogonal (or conversely, paralell)\" the SVM decision boundary is to the basis vector inferred by a neuron. Note that this measure is relative, so it just means how important is a neuron RELATIVE to the other neurons in making the decision. The importance measure will always sum to 1 over all the neurons/features of the classifier. In other words, if all neurons are (equally) redundant, or if all neurons are (equally) important for the classification, both cases leads to the same relative importance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(nfeatures),relative_feature_importance(clf['svc'].coef_[0]))\n",
    "plt.ylabel(\"Relative Neuron Importance\")\n",
    "plt.xlabel(\"Neuron idx\")\n",
    "plt.xticks(range(nfeatures),labels=unit_idnums);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to decision boundary\n",
    "Plot the distribution of distances to the decision boundary. This shows how \"robustly\" different samples have been classified. The further a datapoint is from the decison boundary, the \"more certain\" the classifier is in its decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = distance_to_boundary(X_test,clf['svc'],y_test)\n",
    "nbins=20\n",
    "bins = np.linspace(np.min(dists),np.max(dists),nbins+1)\n",
    "dists_c1 = dists[y_test == categories_to_include[0]]\n",
    "dists_c2 = dists[y_test == categories_to_include[1]]\n",
    "plt.hist(dists_c1,bins,density=True,alpha=0.4,label='C1')\n",
    "plt.hist(dists_c2,bins,density=True,alpha=0.4,label='C2')\n",
    "plt.axvline(0,ls=':')\n",
    "plt.xlabel('Distance to decision boundary')\n",
    "plt.ylabel('Density')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ratemaps of units involved in SVM-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort on unit id\n",
    "figscale = 1\n",
    "from plotting_functions import axis_off_labels_on\n",
    "\n",
    "add_title = True\n",
    "spatial_map = sp.SpatialMap()\n",
    "for unit_idnum in unit_idnums:\n",
    "    unit_spikes = [spike_train for spike_train in spikes if spike_train.annotations[\"unit_idnum\"] == unit_idnum]\n",
    "    fig,axs = plt.subplots(ncols=len(unit_spikes),figsize=(len(unit_spikes)*figscale, 1*figscale))\n",
    "    \n",
    "    for ax, spike_train in zip(axs, unit_spikes):\n",
    "        x,y,t,_ = tracking[spike_train.annotations[\"action_id\"]].T\n",
    "        ratemap = spatial_map.rate_map(x, y, t, spike_train)\n",
    "        ax.imshow(ratemap.T,origin='lower')\n",
    "        axis_off_labels_on(ax)\n",
    "        \n",
    "        # add action_id title to first few plots\n",
    "        if add_title:\n",
    "            ax.set_title(spike_train.annotations[\"action_id\"])\n",
    "    add_title = False\n",
    "    \n",
    "    axs[0].set_ylabel(spike_train.annotations[\"unit_idnum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
